{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder object\n",
    "\n",
    "Nilearn has since release 0.7.0 a new decoder object:\n",
    "\n",
    "- `nilearn.decoding.Decoder` for classification and \n",
    "- `nilearn.decoding.DecoderRegressor` for regression\n",
    "\n",
    "The decoder object implements a model selection scheme that averages the best models within a cross validation loop.\n",
    "\n",
    "## Outline\n",
    "\n",
    "- <a href=\"#decoding\">I. What is decoding?</a>\n",
    "- <a href=\"#classif\">II. Decoder for classification</a>\n",
    "    - <a href=\"#classif-example\">Example</a>\n",
    "        - <a href=\"#classif-example-data\">Get the data</a>\n",
    "        - <a href=\"#classif-example-decoding\">Decoding pipeline</a>\n",
    "        - <a href=\"#classif-example-cross\">How to perform cross validation?</a>\n",
    "        - <a href=\"#classif-example-leave\">Leave one group out cross validation</a>\n",
    "        - <a href=\"#classif-example-chance\">What is the chance level accuracy?</a>\n",
    "    - <a href=\"#classif-compare\">Why is the decoder useful?</a>\n",
    "- III. Decoder for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span id=\"decoding\"></span>\n",
    "\n",
    "## I - What is decoding?\n",
    "\n",
    "Decoding can be seen as the task of predicting from fMRI activity. A good example is the Haxby experiment in which subjects were presented visual stimuli from different categories. Decoding in this context means predicting which category the subject is seeing from the fMRI activity recorded in regions of the ventral visual system. Significant prediction shows that the signal in the region contains information on the corresponding category.\n",
    "\n",
    "**TODO: Add a picture here**\n",
    "\n",
    "If you are not familiar with decoding, we recommand that you read the *introduction to decoding* tutorial on nilearn's website [here](http://nilearn.github.io/decoding/decoding_intro.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span id=\"classif\"></span>\n",
    "\n",
    "## II - Decoder for classification\n",
    "\n",
    "First of all, make sure you have nilearn >= 0.7.0 installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7.2.dev\n"
     ]
    }
   ],
   "source": [
    "import nilearn\n",
    "print(nilearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentation for the classification decoder is available on the website [here](http://nilearn.github.io/modules/generated/nilearn.decoding.Decoder.html#nilearn.decoding.Decoder), or through the Jupyter magic command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mscreening_percentile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msmoothing_fwhm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstandardize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtarget_affine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtarget_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmask_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'background'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlow_pass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhigh_pass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mt_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmemory_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "A wrapper for popular classification strategies in neuroimaging.\n",
       "\n",
       "The `Decoder` object supports classification methods.\n",
       "It implements a model selection scheme that averages the best models\n",
       "within a cross validation loop. The resulting average model is the\n",
       "one used as a classifier. This object also leverages the`NiftiMaskers` to\n",
       "provide a direct interface with the Nifti files on disk.\n",
       "\n",
       "Parameters\n",
       "-----------\n",
       "estimator: str, optional\n",
       "    The estimator to choose among: 'svc', 'svc_l2', 'svc_l1', 'logistic',\n",
       "    'logistic_l1', 'logistic_l2' and 'ridge_classifier'. Note that\n",
       "    'svc' and 'svc_l2'; 'logistic' and 'logistic_l2' correspond to the same\n",
       "    estimator. Dummy classifier is named as 'dummy_classifier'. Default 'svc'.\n",
       "\n",
       "mask: filename, Nifti1Image, NiftiMasker, or MultiNiftiMasker, optional\n",
       "    Mask to be used on data. If an instance of masker is passed,\n",
       "    then its mask and parameters will be used. If no mask is given, mask\n",
       "    will be computed automatically from provided images by an inbuilt\n",
       "    masker with default parameters. Refer to NiftiMasker or\n",
       "    MultiNiftiMasker to check for default parameters. Default None\n",
       "\n",
       "cv: cross-validation generator or int, optional (default 10)\n",
       "    A cross-validation generator.\n",
       "    See: https://scikit-learn.org/stable/modules/cross_validation.html\n",
       "\n",
       "param_grid: dict of str to sequence, or sequence of such. Default None\n",
       "    The parameter grid to explore, as a dictionary mapping estimator\n",
       "    parameters to sequences of allowed values.\n",
       "\n",
       "    None or an empty dict signifies default parameters.\n",
       "\n",
       "    A sequence of dicts signifies a sequence of grids to search, and is\n",
       "    useful to avoid exploring parameter combinations that make no sense\n",
       "    or have no effect. See scikit-learn documentation for more information,\n",
       "    for example: https://scikit-learn.org/stable/modules/grid_search.html\n",
       "\n",
       "    For DummyClassifier, parameter grid defaults to empty dictionary, class\n",
       "    predictions are estimated using default strategy.\n",
       "\n",
       "screening_percentile: int, float, optional, in the closed interval [0, 100]\n",
       "    The percentage of brain volume that will be kept with respect to a full\n",
       "    MNI template. In particular, if it is lower than 100, a univariate\n",
       "    feature selection based on the Anova F-value for the input data will be\n",
       "    performed. A float according to a percentile of the highest\n",
       "    scores. Default: 20.\n",
       "\n",
       "scoring: str, callable or None, optional. Default: 'roc_auc'\n",
       "    The scoring strategy to use. See the scikit-learn documentation at\n",
       "    https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules\n",
       "    If callable, takes as arguments the fitted estimator, the\n",
       "    test data (X_test) and the test target (y_test) if y is\n",
       "    not None.\n",
       "    e.g. scorer(estimator, X_test, y_test)\n",
       "\n",
       "    For classification, valid entries are: 'accuracy', 'f1', 'precision',\n",
       "    'recall' or 'roc_auc'. Default: 'roc_auc'.\n",
       "\n",
       "smoothing_fwhm: float, optional. Default: None\n",
       "    If smoothing_fwhm is not None, it gives the size in millimeters of the\n",
       "    spatial smoothing to apply to the signal.\n",
       "\n",
       "standardize: bool, optional. Default: True\n",
       "    If standardize is True, the time-series are centered and normed:\n",
       "    their variance is put to 1 in the time dimension.\n",
       "\n",
       "target_affine: 3x3 or 4x4 matrix, optional. Default: None\n",
       "    This parameter is passed to image.resample_img. Please see the\n",
       "    related documentation for details.\n",
       "\n",
       "target_shape: 3-tuple of int, optional. Default: None\n",
       "    This parameter is passed to image.resample_img. Please see the\n",
       "    related documentation for details.\n",
       "\n",
       "low_pass: None or float, optional\n",
       "    This parameter is passed to signal.clean. Please see the related\n",
       "    documentation for details\n",
       "\n",
       "high_pass: None or float, optional\n",
       "    This parameter is passed to signal.clean. Please see the related\n",
       "    documentation for details\n",
       "\n",
       "t_r: float, optional. Default: None\n",
       "    This parameter is passed to signal.clean. Please see the related\n",
       "    documentation for details.\n",
       "\n",
       "mask_strategy: {'background' or 'epi'}, optional. Default: 'background'\n",
       "    The strategy used to compute the mask: use 'background' if your\n",
       "    images present a clear homogeneous background, and 'epi' if they\n",
       "    are raw EPI images. Depending on this value, the mask will be\n",
       "    computed from masking.compute_background_mask or\n",
       "    masking.compute_epi_mask.\n",
       "\n",
       "    This parameter will be ignored if a mask image is provided.\n",
       "\n",
       "memory: instance of joblib.Memory or str\n",
       "    Used to cache the masking process.\n",
       "    By default, no caching is done. If a str is given, it is the\n",
       "    path to the caching directory.\n",
       "\n",
       "memory_level: int, optional. Default: 0\n",
       "    Rough estimator of the amount of memory used by caching. Higher value\n",
       "    means more memory for caching.\n",
       "\n",
       "n_jobs: int, optional. Default: 1.\n",
       "    The number of CPUs to use to do the computation. -1 means\n",
       "    'all CPUs'.\n",
       "\n",
       "verbose: int, optional. Default: 0.\n",
       "    Verbosity level.\n",
       "\n",
       "See Also\n",
       "------------\n",
       "nilearn.decoding.DecoderRegressor: regression strategies for Neuro-imaging,\n",
       "nilearn.decoding.FREMClassifier: State of the art classification pipeline\n",
       "    for Neuroimaging\n",
       "nilearn.decoding.SpaceNetClassifier: Graph-Net and TV-L1 priors/penalties\n",
       "\u001b[0;31mFile:\u001b[0m           ~/GitRepos/nilearn-fork/nilearn/decoding/decoder.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nilearn.decoding import Decoder\n",
    "?Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span id=\"classif-example\"></span>\n",
    "\n",
    "### Example\n",
    "\n",
    "<span id=\"classif-example-data\"></span>\n",
    "\n",
    "#### Get the data\n",
    "\n",
    "As an example, we will use the Haxby dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/GitRepos/nilearn-fork/nilearn/datasets/__init__.py:87: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['anat', 'func', 'session_target', 'mask_vt', 'mask_face', 'mask_house', 'mask_face_little', 'mask_house_little', 'mask', 'description'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nilearn.datasets import fetch_haxby\n",
    "\n",
    "haxby_dataset = fetch_haxby()\n",
    "haxby_dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 64, 64, 1452)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nilearn.image import load_img\n",
    "load_img(haxby_dataset.func[0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the data is quite large and contains many conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     labels  chunks\n",
      "0      rest       0\n",
      "1      rest       0\n",
      "2      rest       0\n",
      "3      rest       0\n",
      "4      rest       0\n",
      "...     ...     ...\n",
      "1447   rest      11\n",
      "1448   rest      11\n",
      "1449   rest      11\n",
      "1450   rest      11\n",
      "1451   rest      11\n",
      "\n",
      "[1452 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load behavioral information\n",
    "import pandas as pd\n",
    "\n",
    "behavioral = pd.read_csv(haxby_dataset.session_target[0], delimiter=' ')\n",
    "print(behavioral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bottle', 'cat', 'chair', 'face', 'house', 'rest', 'scissors',\n",
       "       'scrambledpix', 'shoe'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What conditions do we have in this dataset?\n",
    "import numpy as np\n",
    "conditions = behavioral['labels']\n",
    "np.unique(conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to simplify this example, we will focus only on `cats` and `faces` signals. We need to drop all data unrelated to these signals. One way to do that is to create a condition mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_mask = conditions.isin(['face', 'cat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use this condition mask to restrict our analysis to cats and faces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 64, 64, 216)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nilearn.image import index_img\n",
    "\n",
    "cats_and_faces_data = index_img(haxby_dataset.func[0], \n",
    "                                condition_mask)\n",
    "load_img(cats_and_faces_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions = conditions[condition_mask].values\n",
    "conditions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now a much smaller dataset to work on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span id=\"classif-example-decoding\"></span>\n",
    "\n",
    "#### Decoding basic pipeline\n",
    "\n",
    "We now have everything we need to do some decoding.\n",
    "\n",
    "The Decoder object follows the usual `fit`, `transform`, `predict` pattern from scikit-learn such that you usually follow the following pattern:\n",
    "\n",
    "- Instanciate the Decoder with chosen parameters (estimator, mask...)\n",
    "- Fit the decoder on training set\n",
    "- Predict on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(estimator='svc',               # Use Support Vector Classifier \n",
    "                  mask=haxby_dataset.mask_vt[0], # Provide a mask of the Ventral Temporal cortex\n",
    "                  standardize=True)              # Standardize time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets pretend we have a training set and a test set by leaving out the last 30 samples and predicting on these samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = index_img(cats_and_faces_data, slice(0, -30))    # train set is all but last 30 samples\n",
    "test  = index_img(cats_and_faces_data, slice(-30, None)) # test set is only the last 30 samples\n",
    "conditions_train = conditions[:-30]\n",
    "conditions_test = conditions[-30:]\n",
    "\n",
    "# We fit our decoder on the train set\n",
    "decoder.fit(train, conditions_train)\n",
    "\n",
    "# And predict on the test set\n",
    "prediction = decoder.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to quantify how well we are doing, we can compute the prediction accuracy on the test set, which is the proportion of correctly classified samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 0.767\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction Accuracy: {:.3f}\".format(\n",
    "    (prediction == conditions_test).sum() / float(len(conditions_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span id=\"classif-example-cross\"></span>\n",
    "\n",
    "#### Cross Validation\n",
    "\n",
    "The decoder also implements a cross-validation loop by default and returns an array of shape (cross-validation parameters, n_folds). We can use accuracy score to measure its performance by defining accuracy as the scoring parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "decoder = Decoder(estimator='svc', \n",
    "                  mask=haxby_dataset.mask_vt[0],\n",
    "                  standardize=True,\n",
    "                  cv=n_folds,\n",
    "                  scoring='accuracy')\n",
    "decoder.fit(cats_and_faces_data,\n",
    "            conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then check the scores and best performing params per fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': [0.9772727272727273,\n",
       "  0.7906976744186046,\n",
       "  0.7441860465116279,\n",
       "  0.8372093023255814,\n",
       "  0.813953488372093],\n",
       " 'face': [0.9772727272727273,\n",
       "  0.7906976744186046,\n",
       "  0.7441860465116279,\n",
       "  0.8372093023255814,\n",
       "  0.813953488372093]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.cv_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': {'C': [100.0, 100.0, 100.0, 100.0, 100.0]},\n",
       " 'face': {'C': [100.0, 100.0, 100.0, 100.0, 100.0]}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.cv_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span id=\"classif-example-leave\"></span>\n",
    "\n",
    "#### Leave one group out cross validation\n",
    "\n",
    "The best way to do cross-validation is to respect the structure of the experiment, for instance by leaving out full sessions of acquisition.\n",
    "\n",
    "The number of the session is stored in the CSV file giving the behavioral data. We have to apply our session mask, to select only cats and faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_label = behavioral['chunks'][condition_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fMRI data is acquired by sessions, and the noise is autocorrelated in a given session. Hence, it is better to predict across sessions when doing cross-validation. To leave a session out, pass the cross-validator object to the cv parameter of decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cat': [1.0, 1.0, 1.0, 1.0, 0.9629629629629629, 0.8518518518518519, 0.9753086419753086, 0.40740740740740744, 0.9876543209876543, 1.0, 0.9259259259259259, 0.8765432098765432], 'face': [1.0, 1.0, 1.0, 1.0, 0.9629629629629629, 0.8518518518518519, 0.9753086419753086, 0.40740740740740744, 0.9876543209876543, 1.0, 0.9259259259259259, 0.8765432098765432]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "cv = LeaveOneGroupOut()\n",
    "\n",
    "decoder = Decoder(estimator='svc', \n",
    "                  mask=haxby_dataset.mask_vt[0], \n",
    "                  standardize=True,\n",
    "                  cv=cv)\n",
    "decoder.fit(cats_and_faces_data, \n",
    "            conditions, \n",
    "            groups=session_label)\n",
    "print(decoder.cv_scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span id=\"classif-example-chance\"></span>\n",
    "\n",
    "#### Chance level accuracy\n",
    "\n",
    "Does the model above perform better than chance? \n",
    "\n",
    "To answer this question, we measure a score at random using simple strategies that are implemented in the `Decoder` object. This is useful to inspect the decoding performance by comparing to a score at chance.\n",
    "\n",
    "Let’s define a object with Dummy estimator replacing ‘svc’ for classification setting. This object initializes estimator with default dummy strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cat': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], 'face': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]}\n"
     ]
    }
   ],
   "source": [
    "dummy_decoder = Decoder(estimator='dummy_classifier', \n",
    "                        mask=haxby_dataset.mask_vt[0],\n",
    "                        cv=cv)\n",
    "dummy_decoder.fit(cats_and_faces_data, \n",
    "                  conditions, \n",
    "                  groups=session_label)\n",
    "# Now, we can compare these scores by simply taking a mean over folds\n",
    "print(dummy_decoder.cv_scores_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span id=\"classif-compare\"></span>\n",
    "\n",
    "### Why is the decoder object useful?\n",
    "\n",
    "In this section we will compare the new decoding pipeline resulting from the addition of the decoder object to Nilearn with the previous way of decoding.\n",
    "\n",
    "We keep the same example as before, but we decode as if the decoder didn't exist..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to build X by masking the data\n",
    "from nilearn.input_data import NiftiMasker\n",
    "masker = NiftiMasker(haxby_dataset.mask_vt[0])\n",
    "X = masker.fit_transform(cats_and_faces_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we preprocess our labels to build y\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "target_encoder = LabelBinarizer(pos_label=1, \n",
    "                                neg_label=-1)\n",
    "y = target_encoder.fit_transform(conditions)\n",
    "assert X.shape[0] == y.shape[0] # Make sure we have as many samples as we have labels..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cross validation strategy\n",
    "cv_object = LeaveOneGroupOut()\n",
    "cv_folds  = list(cv_object.split(X, y, \n",
    "                                 groups=session_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and parameterize our estimator (use SVC here, just like above...)\n",
    "from sklearn.svm import LinearSVC\n",
    "estimator = LinearSVC(penalty='l2', # these are the default parameters\n",
    "                      max_iter=1e4) # used in nilearn decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a scoring strategy\n",
    "from sklearn.metrics import get_scorer\n",
    "scorer = get_scorer(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/anaconda3/envs/nilearn/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/nicolas/anaconda3/envs/nilearn/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/nicolas/anaconda3/envs/nilearn/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/nicolas/anaconda3/envs/nilearn/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/nicolas/anaconda3/envs/nilearn/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/nicolas/anaconda3/envs/nilearn/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/nicolas/anaconda3/envs/nilearn/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/nicolas/anaconda3/envs/nilearn/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/nicolas/anaconda3/envs/nilearn/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/nicolas/anaconda3/envs/nilearn/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/nicolas/anaconda3/envs/nilearn/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/nicolas/anaconda3/envs/nilearn/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn import clone\n",
    "scores = []; coefs  = []; intercept = []\n",
    "for train,test in cv_folds:\n",
    "    X_train, y_train = X[train], y[:,0][train]\n",
    "    X_test, y_test   = X[test], y[:,0][test]\n",
    "    estimator_ = clone(estimator)\n",
    "    estimator_.fit(X_train, y_train)\n",
    "    score = scorer(estimator_, X_test, y_test)\n",
    "    scores.append(score)\n",
    "    coefs.append(estimator_.coef_)\n",
    "    intercept.append(estimator_.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_coeff = np.mean(coefs, axis=0)\n",
    "aggregated_intercept = np.mean(intercept, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "scores = safe_sparse_dot(X, aggregated_coeff.T, dense_output=True) + aggregated_intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = (scores > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['face'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat'],\n",
       "       ['cat']], dtype='<U4')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_encoder.classes_[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
